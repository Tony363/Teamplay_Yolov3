# -*- coding: utf-8 -*-
"""Players_mapping_onto_minmap.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ml0dth44Br-mcpRkahyUFs1Xy9xuB5lf

# Creating a basketball mini map using homography transformations

Author Stephan Janssen (sja@devoxx.com)

See also related [article on LinkedIn](https://www.linkedin.com/pulse/journey-towards-creating-basketball-mini-map-stephan-janssen/) and result on [YouTube](https://www.youtube.com/watch?v=tpavRDeDlTI).

We still need to identify the players per team which can be achieved using colour detection, that's not too difficult.

Improvements or suggestions are always welcome!

# Install detectron2
"""

# install dependencies
# !pip install -U torch torchvision cython
# !pip install -U 'git+https://github.com/facebookresearch/fvcore.git' 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'
import torch, torchvision
torch.__version__

# !git clone https://github.com/facebookresearch/detectron2 detectron2_repo
# !pip install -e detectron2_repo

# You may need to restart your runtime prior to this, to let your installation take effect

# Some basic setup

# Setup detectron2 logger
import detectron2
from detectron2.utils.logger import setup_logger
setup_logger()

# import some common libraries
import numpy as np
import cv2
import random


# import some common detectron2 utilities
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog

"""# Run a pre-trained detectron2 model

We first download a random image from the COCO dataset:
"""

# Commented out IPython magic to ensure Python compatibility.
# %ls

# !wget https://basketball-ml.s3-eu-west-1.amazonaws.com/3DVideoFrame.jpg -O input.jpg
im = cv2.imread("images/basketball.png")
cv2.imshow('image',im)
# cv2.waitKey(1000)

"""Then, we create a detectron2 config and a detectron2 `DefaultPredictor` to run inference on this image."""

cfg = get_cfg()
cfg.MODEL.DEVICE = 'cpu' # for cpu usage
cfg.merge_from_file("../../detectron2_repo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")

cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model

cfg.MODEL.WEIGHTS = "detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl"

predictor = DefaultPredictor(cfg)

players_output = predictor(im)

# look at the outputs. See https://detectron2.readthedocs.io/tutorials/models.html#model-output-format for specification
instances = players_output["instances"]
print(instances)
pred_boxes = instances.get("pred_boxes")
pred_classes = instances.get("pred_classes")
print(pred_boxes)
print(pred_classes)

# We can use `Visualizer` to draw the predictions on the image.
v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.0)
v = v.draw_instance_predictions(players_output["instances"].to("cpu"))
cv2.imshow('detect box',v.get_image()[:, :, ::-1])
# cv2.waitKey(1000)

# Four corners of the 3D court 
# Start top-left corner and go anti-clock wise
src_pts = np.array(
        [[  67, 1063],
 [ 526,  744],
 [ 909,  542],
 [1197,  438],
 [1740,  415],
 [2418,  475],
 [3157,  635],
 [3609,  785],
 [3855,  951],
 [4148, 1226],
 [4516, 1598],
 [3941, 1763],
 [2228, 1836],
 [ 690, 1365]]
    )   

im_poly = im.copy()

# cv2.fillPoly(img_src, [src_pts], 255)
cv2.polylines(im_poly, [src_pts], isClosed=True, color=[255,0,0], thickness=2)

cv2.imshow('polylines',im_poly)
# cv2.waitKey(1000)

# Use the boxes info from the tensor prediction result
# #
# x1,y1 ------
# |          |
# |          |
# |          |
# --------x2,y2
#
from shapely.geometry import Point, Polygon

def drawPlayers(im, pred_boxes, showResult=False):
  color = [255, 0, 0]   
  thickness = 1
  radius = 1

  i  = 0
  for box in pred_boxes:
    
    # Include only class Person
    if pred_classes[i] == 0:  
        
      x1 = int(box[0])
      y1 = int(box[1])
      x2 = int(box[2])
      y2 = int(box[3])

      xc = x1 + int((x2 - x1)/2)
      player_pos1 = (xc - 1, y2)
      player_pos2 = (xc + 1, y2 + 1)

      court = Polygon(src_pts)

      # Draw only players that are within the basketball court
      if Point(player_pos1).within(court):
        if showResult:
          print("[% 3d, % 3d]" %(xc, y2))

      cv2.rectangle(im, player_pos1, player_pos2, color, thickness)
      i = i + 1            

  if showResult:
    cv2.imshow('drawPlayers',im)
    # cv2.waitKey(1000)


drawPlayers(im, pred_boxes, True)

img_dst = cv2.imread('images/court.png')

# Four corners of the court + mid-court circle point in destination image 
# Start top-left corner and go anti-clock wise + mid-court circle point
# dst_pts = np.array([
#       [144,  1060],  # LEFT BOTTOM
#       [969,  1065],  # MIDDLE BOTTOM
#       [1769, 1063],  # RIGHT BOTTOM
#       [1885, 875],   # TOP BOTTOM RIGHT  (4 o'clock)
#       [1882,  49],   # TOP RIGHT
#       [50,    43],   # TOP LEFT
#       [50,    871]   # TOP - BOTTOM LEFT (7 o'clock)
#     ])   
dst_pts = np.array(
    [[  60, 1059],
 [  56,  682],
 [  47,  431],
 [  54,   42],
 [ 581,   49],
 [ 967 ,  48],
 [1329 ,  46],
 [1881 ,  46],
 [1884 , 438],
 [1876,  680],
 [1876, 1063],
 [1351, 1070],
 [ 967, 1067],
 [ 559, 1071]])
 
cv2.polylines(img_dst, [dst_pts], isClosed=True, color=[255,0,0], thickness=2)
cv2.imshow('polylines',img_dst)
# cv2.waitKey(1000)

def homographyTransform(im, showResult=False):
  # Calculate Homography
  h, status = cv2.findHomography(src_pts, dst_pts)
  img_out = cv2.warpPerspective(im, h, (img_dst.shape[1], img_dst.shape[0]))
  if showResult:
    cv2.imshow('homographyTransform',img_out)
    # cv2.waitKey(1000)

  return img_out  

# Try out
img_out = homographyTransform(im, True)

def getPlayersMask(im):
  lower_range = np.array([255,0,0])                         # Set the Lower range value of blue in BGR
  upper_range = np.array([255,155,155])                     # Set the Upper range value of blue in BGR
  mask = cv2.inRange(im, lower_range, upper_range)     # Create a mask with range
  result = cv2.bitwise_and(im, img_out, mask = mask)   # Performing bitwise and operation with mask in img variable
  # cv2_imshow(result)                           
  return cv2.inRange(result, lower_range, upper_range)  
  
# Try out  
mask = getPlayersMask(img_out)    
cv2.imshow('mask',mask)
# cv2.waitKey(1000)

def drawPlayersOnCourt(im, coord, color, radius=10):
  # print(coord)
  for pos in coord:
    center_coordinates = (pos[0], pos[1])
    cv2.circle(im, center_coordinates, radius, color, thickness=-1) 
  return im

"""Now lets create a mini-map based on a 30 seconds basketball game."""



# Draft method to draw lines between history player positions to show trail
def drawCoordinateLines(result, pts, currentFrame, player):
  
  for i in np.arange(1, len(pts)):
    
    # if either of the tracked points are None, ignore them
    if pts[i - 1] is None or pts[i] is None:
      continue

    thickness = int(np.sqrt(30 / float(i + 1)) * 2.5)
    print("player=%s" %player)
    x1 = pts[i - 1][0][0]
    x2 = pts[i - 1][0][1]
    print("x1=%d, x2=%d" %(x1, x2))
    y1 = pts[i][0][0]
    y2 = pts[i][0][1]
    print("y1=%d, y2=%d" %(y1, y2))
    print(" ---------------------- ")
    cv2.line(result, (x1, x2), (y1, y2), red_color, thickness)

  return result

import time
import progressbar
from time import sleep
from collections import deque
from detectron2.utils.visualizer import ColorMode
from detectron2.utils.visualizer import GenericMask
import imutils

vs = cv2.VideoCapture("../input_vid/result_video.mp4")
totalFrames = int(vs.get(cv2.CAP_PROP_FRAME_COUNT))

grabbed = True
currentFrame = 0
start = time.time()
writer = None
box_writer = None

bar = progressbar.ProgressBar(maxval=totalFrames, \
      widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])

bar.start()

court_img = cv2.imread('images/court.png')

blue_color = (255,0,0)
red_color = (0,0,255)

# loop over frames from the video file stream (207)
while grabbed:     
  # read the next frame from the file
  (grabbed, frame) = vs.read()
  
  if writer is None and box_writer is None:
    fps = vs.get(cv2.CAP_PROP_FPS)
    fourcc = cv2.VideoWriter_fourcc(*"mp4v")
    writer = cv2.VideoWriter("tennis_homographic.mp4", fourcc, fps, (court_img.shape[1], court_img.shape[0]), True)
    # box_writer = cv2.VideoWriter("player_box.mp4",fourcc,fps,(im.shape[1],im.shape[0]),True)
  if grabbed:
    # print(currentFrame)
    # players_output = predictor(frame)# predict on frame
    # Get player positions
    outputs = predictor(frame)  
    instances = outputs["instances"].to("cpu")
    boxes = instances.get("pred_boxes")

    # v = Visualizer(frame[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.0)
    # v = v.draw_instance_predictions(output["instances"].to("cpu"))
 
    court = court_img.copy()

    # Draw players on video frame
    drawPlayers(frame, boxes, False)
    
    img_out = homographyTransform(frame, False)
    cv2.imshow('homographyTransform',img_out)

    mask = getPlayersMask(img_out)
    # print(mask)
    cv2.imshow('mask',mask)
    

    # Get the contours from the players "dots" so we can reduce the coordinates
    # to the number of players on the court.
    cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    # print(cnts)
    cnts = imutils.grab_contours(cnts)

    if cnts is not None:  
      # print(cnts)   
      for cnt in cnts:
        result = drawPlayersOnCourt(court, cnt[0], blue_color)
                               
      writer.write(result)
      # box_writer.write(v.get_image()[:, :, ::-1])

    currentFrame += 1
    bar.update(currentFrame)
  
  else:
      grabbed = False

# cv2_imshow(result)
    
writer.release()
# box_writer.release()
vs.release()
bar.finish()

end = time.time()
elap = (end - start)
print("[INFO] process took {:.4f} seconds".format(elap))

print("Video created")